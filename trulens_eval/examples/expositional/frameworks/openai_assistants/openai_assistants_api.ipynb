{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI Assitants API\n",
    "\n",
    "The [Assistants API](https://platform.openai.com/docs/assistants/overview) allows you to build AI assistants within your own applications. An Assistant has instructions and can leverage models, tools, and knowledge to respond to user queries. The Assistants API currently supports three types of tools: Code Interpreter, Retrieval, and Function calling.\n",
    "\n",
    "TruLens can be easily integrated with the assistants API to provide the same observability tooling you are used to when building with other frameworks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "[**Important**] Notice in this example notebook, we are using Assistants API V1 (hence the pinned version of `openai` below) so that we can evaluate against retrieved source.\n",
    "At some very recent point in time as of April 2024, OpenAI removed the [\"quote\" attribute from file citation object in Assistants API V2](https://platform.openai.com/docs/api-reference/messages/object#messages/object-content) due to stability issue of this feature. See response from OpenAI staff https://community.openai.com/t/assistant-api-always-return-empty-annotations/489285/48\n",
    "\n",
    "Here's the migration guide for easier navigating between V1 and V2 of Assistants API: https://platform.openai.com/docs/assistants/migration/changing-beta-versions\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install trulens-eval openai==1.14.3 # pinned openai version to avoid breaking changes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-...\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the assistant\n",
    "\n",
    "Let's create a new assistant that answers questions about the famous *Paul Graham Essay*.\n",
    "\n",
    "The easiest way to get it is to download it via this link and save it in a folder called data. You can do so with the following command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-04-25 18:07:33--  https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/paul_graham/paul_graham_essay.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 75042 (73K) [text/plain]\n",
      "Saving to: â€˜data/paul_graham_essay.txt.2â€™\n",
      "\n",
      "paul_graham_essay.t 100%[===================>]  73.28K  --.-KB/s    in 0.007s  \n",
      "\n",
      "2024-04-25 18:07:33 (9.58 MB/s) - â€˜data/paul_graham_essay.txt.2â€™ saved [75042/75042]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/paul_graham/paul_graham_essay.txt -P data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add TruLens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦‘ Tru initialized with db url sqlite:///default.sqlite .\n",
      "ðŸ›‘ Secret keys may be written to the database. See the `database_redact_keys` option of Tru` to prevent this.\n"
     ]
    }
   ],
   "source": [
    "from trulens_eval import Tru\n",
    "from trulens_eval.tru_custom_app import instrument\n",
    "tru = Tru()\n",
    "tru.reset_database()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a thread (V1 Assistants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "class RAG_with_OpenAI_Assistant:\n",
    "    def __init__(self):\n",
    "        client = OpenAI()\n",
    "        self.client = client\n",
    "\n",
    "        # upload the file\\\n",
    "        file = client.files.create(\n",
    "        file=open(\"data/paul_graham_essay.txt\", \"rb\"),\n",
    "        purpose='assistants'\n",
    "        )\n",
    "\n",
    "        # create the assistant with access to a retrieval tool\n",
    "        assistant = client.beta.assistants.create(\n",
    "            name=\"Paul Graham Essay Assistant\",\n",
    "            instructions=\"You are an assistant that answers questions about Paul Graham.\",\n",
    "            tools=[{\"type\": \"retrieval\"}],\n",
    "            model=\"gpt-4-turbo-preview\",\n",
    "            file_ids=[file.id]\n",
    "        )\n",
    "        \n",
    "        self.assistant = assistant\n",
    "\n",
    "    @instrument\n",
    "    def retrieve_and_generate(self, query: str) -> str:\n",
    "        \"\"\"\n",
    "        Retrieve relevant text by creating and running a thread with the OpenAI assistant.\n",
    "        \"\"\"\n",
    "        self.thread = self.client.beta.threads.create()\n",
    "        self.message = self.client.beta.threads.messages.create(\n",
    "            thread_id=self.thread.id,\n",
    "            role=\"user\",\n",
    "            content=query\n",
    "        )\n",
    "\n",
    "        run = self.client.beta.threads.runs.create(\n",
    "            thread_id=self.thread.id,\n",
    "            assistant_id=self.assistant.id,\n",
    "            instructions=\"Please answer any questions about Paul Graham.\"\n",
    "        )\n",
    "\n",
    "        # Wait for the run to complete\n",
    "        import time\n",
    "        while run.status in ['queued', 'in_progress', 'cancelling']:\n",
    "            time.sleep(1)\n",
    "            run = self.client.beta.threads.runs.retrieve(\n",
    "                thread_id=self.thread.id,\n",
    "                run_id=run.id\n",
    "            )\n",
    "\n",
    "        if run.status == 'completed':\n",
    "            messages = self.client.beta.threads.messages.list(\n",
    "                thread_id=self.thread.id\n",
    "            )\n",
    "            response = messages.data[0].content[0].text.value\n",
    "            quote = messages.data[0].content[0].text.annotations[0].file_citation.quote\n",
    "        else:\n",
    "            response = \"Unable to retrieve information at this time.\"\n",
    "\n",
    "        return response, quote\n",
    "    \n",
    "rag = RAG_with_OpenAI_Assistant()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create feedback functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… In Groundedness, input source will be set to __record__.app.retrieve_and_generate.rets[1] .\n",
      "âœ… In Groundedness, input statement will be set to __record__.app.retrieve_and_generate.rets[0] .\n",
      "âœ… In Answer Relevance, input prompt will be set to __record__.app.retrieve_and_generate.args.query .\n",
      "âœ… In Answer Relevance, input response will be set to __record__.app.retrieve_and_generate.rets[0] .\n",
      "âœ… In Context Relevance, input question will be set to __record__.app.retrieve_and_generate.args.query .\n",
      "âœ… In Context Relevance, input context will be set to __record__.app.retrieve_and_generate.rets[1] .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/daniel/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from trulens_eval import Feedback, Select\n",
    "from trulens_eval.feedback import Groundedness\n",
    "from trulens_eval.feedback.provider.openai import OpenAI\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "provider = OpenAI()\n",
    "\n",
    "grounded = Groundedness(groundedness_provider=provider)\n",
    "\n",
    "# Define a groundedness feedback function\n",
    "f_groundedness = (\n",
    "    Feedback(grounded.groundedness_measure_with_cot_reasons, name = \"Groundedness\")\n",
    "    .on(Select.RecordCalls.retrieve_and_generate.rets[1])\n",
    "    .on(Select.RecordCalls.retrieve_and_generate.rets[0])\n",
    "    .aggregate(grounded.grounded_statements_aggregator)\n",
    ")\n",
    "\n",
    "# Question/answer relevance between overall question and answer.\n",
    "f_answer_relevance = (\n",
    "    Feedback(provider.relevance_with_cot_reasons, name = \"Answer Relevance\")\n",
    "    .on(Select.RecordCalls.retrieve_and_generate.args.query)\n",
    "    .on(Select.RecordCalls.retrieve_and_generate.rets[0])\n",
    ")\n",
    "\n",
    "# Question/statement relevance between question and each context chunk.\n",
    "f_context_relevance = (\n",
    "    Feedback(provider.context_relevance_with_cot_reasons, name = \"Context Relevance\")\n",
    "    .on(Select.RecordCalls.retrieve_and_generate.args.query)\n",
    "    .on(Select.RecordCalls.retrieve_and_generate.rets[1])\n",
    "    .aggregate(np.mean)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens_eval import TruCustomApp\n",
    "tru_rag = TruCustomApp(rag,\n",
    "    app_id = 'OpenAI Assistant RAG',\n",
    "    feedbacks = [f_groundedness, f_answer_relevance, f_context_relevance])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tru_rag:\n",
    "    rag.retrieve_and_generate(\"How did paul graham grow up?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Groundedness</th>\n",
       "      <th>Answer Relevance</th>\n",
       "      <th>Context Relevance</th>\n",
       "      <th>latency</th>\n",
       "      <th>total_cost</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>app_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>OpenAI Assistant RAG</th>\n",
       "      <td>0.307692</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Groundedness  Answer Relevance  Context Relevance  \\\n",
       "app_id                                                                    \n",
       "OpenAI Assistant RAG      0.307692               1.0                0.4   \n",
       "\n",
       "                      latency  total_cost  \n",
       "app_id                                     \n",
       "OpenAI Assistant RAG     38.0         0.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from trulens_eval import Tru\n",
    "\n",
    "tru.get_leaderboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tru.run_dashboard() # alternatively, you can also run `trulens-eval` from the terminal in the same folder containing the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai-prospector",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
