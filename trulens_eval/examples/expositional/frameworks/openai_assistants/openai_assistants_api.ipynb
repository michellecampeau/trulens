{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI Assitants API\n",
    "\n",
    "The [Assistants API](https://platform.openai.com/docs/assistants/overview) allows you to build AI assistants within your own applications. An Assistant has instructions and can leverage models, tools, and knowledge to respond to user queries. The Assistants API currently supports three types of tools: Code Interpreter, Retrieval, and Function calling.\n",
    "\n",
    "TruLens can be easily integrated with the assistants API to provide the same observability tooling you are used to when building with other frameworks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-...\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the assistant\n",
    "\n",
    "Let's create a new assistant that answers questions about the famous *Paul Graham Essay*.\n",
    "\n",
    "The easiest way to get it is to download it via this link and save it in a folder called data. You can do so with the following command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/paul_graham/paul_graham_essay.txt -P data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens_eval import Tru\n",
    "\n",
    "tru = Tru()\n",
    "\n",
    "tru.reset_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add TruLens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens_eval import Tru\n",
    "from trulens_eval.tru_custom_app import instrument\n",
    "tru = Tru()\n",
    "tru.reset_database()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAG_with_OpenAI_Assistant:\n",
    "    def __init__(self):\n",
    "        client = OpenAI()\n",
    "        self.client = client\n",
    "\n",
    "        # upload the file\\\n",
    "        file = client.files.create(\n",
    "        file=open(\"data/paul_graham_essay.txt\", \"rb\"),\n",
    "        purpose='assistants'\n",
    "        )\n",
    "\n",
    "        # create the assistant with access to a retrieval tool\n",
    "        assistant = client.beta.assistants.create(\n",
    "            name=\"Paul Graham Essay Assistant\",\n",
    "            instructions=\"You are an assistant that answers questions about Paul Graham.\",\n",
    "            tools=[{\"type\": \"retrieval\"}],\n",
    "            model=\"gpt-4-turbo-preview\",\n",
    "            file_ids=[file.id]\n",
    "        )\n",
    "        \n",
    "        self.assistant = assistant\n",
    "\n",
    "    @instrument\n",
    "    def retrieve_and_generate(self, query: str) -> str:\n",
    "        \"\"\"\n",
    "        Retrieve relevant text by creating and running a thread with the OpenAI assistant.\n",
    "        \"\"\"\n",
    "        self.thread = self.client.beta.threads.create()\n",
    "        self.message = self.client.beta.threads.messages.create(\n",
    "            thread_id=self.thread.id,\n",
    "            role=\"user\",\n",
    "            content=query\n",
    "        )\n",
    "\n",
    "        run = self.client.beta.threads.runs.create(\n",
    "            thread_id=self.thread.id,\n",
    "            assistant_id=self.assistant.id,\n",
    "            instructions=\"Please answer any questions about Paul Graham.\"\n",
    "        )\n",
    "\n",
    "        # Wait for the run to complete\n",
    "        import time\n",
    "        while run.status in ['queued', 'in_progress', 'cancelling']:\n",
    "            time.sleep(1)\n",
    "            run = self.client.beta.threads.runs.retrieve(\n",
    "                thread_id=self.thread.id,\n",
    "                run_id=run.id\n",
    "            )\n",
    "\n",
    "        if run.status == 'completed':\n",
    "            messages = self.client.beta.threads.messages.list(\n",
    "                thread_id=self.thread.id\n",
    "            )\n",
    "            response = messages.data[0].content[0].text.value\n",
    "            quote = messages.data[0].content[0].text.annotations[0].file_citation.quote\n",
    "        else:\n",
    "            response = \"Unable to retrieve information at this time.\"\n",
    "\n",
    "        return response, quote\n",
    "    \n",
    "rag = RAG_with_OpenAI_Assistant()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create feedback functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens_eval import Feedback, Select\n",
    "from trulens_eval.feedback import Groundedness\n",
    "from trulens_eval.feedback.provider.openai import OpenAI\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "provider = OpenAI()\n",
    "\n",
    "grounded = Groundedness(groundedness_provider=provider)\n",
    "\n",
    "# Define a groundedness feedback function\n",
    "f_groundedness = (\n",
    "    Feedback(grounded.groundedness_measure_with_cot_reasons, name = \"Groundedness\")\n",
    "    .on(Select.RecordCalls.retrieve_and_generate.rets[1])\n",
    "    .on(Select.RecordCalls.retrieve_and_generate.rets[0])\n",
    "    .aggregate(grounded.grounded_statements_aggregator)\n",
    ")\n",
    "\n",
    "# Question/answer relevance between overall question and answer.\n",
    "f_answer_relevance = (\n",
    "    Feedback(provider.relevance_with_cot_reasons, name = \"Answer Relevance\")\n",
    "    .on(Select.RecordCalls.retrieve_and_generate.args.query)\n",
    "    .on(Select.RecordCalls.retrieve_and_generate.rets[0])\n",
    ")\n",
    "\n",
    "# Question/statement relevance between question and each context chunk.\n",
    "f_context_relevance = (\n",
    "    Feedback(provider.context_relevance_with_cot_reasons, name = \"Context Relevance\")\n",
    "    .on(Select.RecordCalls.retrieve_and_generate.args.query)\n",
    "    .on(Select.RecordCalls.retrieve_and_generate.rets[1])\n",
    "    .aggregate(np.mean)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens_eval import TruCustomApp\n",
    "tru_rag = TruCustomApp(rag,\n",
    "    app_id = 'OpenAI Assistant RAG',\n",
    "    feedbacks = [f_groundedness, f_answer_relevance, f_context_relevance])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tru_rag:\n",
    "    rag.retrieve_and_generate(\"How did paul graham grow up?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens_eval import Tru\n",
    "\n",
    "tru.get_leaderboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tru.run_dashboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai-prospector",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
