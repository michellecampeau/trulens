{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterating on LLM Apps with TruLens\n",
    "\n",
    "1. Start with basic RAG.\n",
    "2. Show failures of RAG Triad.\n",
    "3. Address failures with context filtering, advanced RAG (e.g., sentence windows, auto-retrieval)\n",
    "4. Showcase experiment tracking to choose best app configuration. \n",
    "5. Weave in different types of evals into narrative\n",
    "6. Weave in user/customer stories into narrative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your API keys. If you already have them in your var env., you can skip these steps.\n",
    "import os\n",
    "import openai\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"...\"\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "os.environ[\"HUGGINGFACE_API_KEY\"] = \"...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens_eval import Tru\n",
    "\n",
    "Tru().reset_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens_eval import Tru\n",
    "\n",
    "tru = Tru()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tru.run_dashboard()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start with basic RAG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import SimpleDirectoryReader\n",
    "\n",
    "documents = SimpleDirectoryReader(\n",
    "    input_files=[\"./Insurance_Handbook_20103.pdf\"]\n",
    ").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import Document\n",
    "\n",
    "from llama_index import ServiceContext, VectorStoreIndex, StorageContext\n",
    "\n",
    "from llama_index.llms import OpenAI\n",
    "\n",
    "# initialize llm\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo\", temperature=0.5)\n",
    "\n",
    "# knowledge store\n",
    "document = Document(text=\"\\n\\n\".join([doc.text for doc in documents]))\n",
    "\n",
    "from llama_index import VectorStoreIndex\n",
    "\n",
    "# service context for index\n",
    "service_context = ServiceContext.from_defaults(\n",
    "        llm=llm,\n",
    "        embed_model=\"local:BAAI/bge-small-en-v1.5\")\n",
    "\n",
    "# create index\n",
    "index = VectorStoreIndex.from_documents([document], service_context=service_context)\n",
    "\n",
    "from llama_index import Prompt\n",
    "\n",
    "system_prompt = Prompt(\"We have provided context information below that you may use. \\n\"\n",
    "    \"---------------------\\n\"\n",
    "    \"{context_str}\"\n",
    "    \"\\n---------------------\\n\"\n",
    "    \"Please answer the question: {query_str}\\n\")\n",
    "\n",
    "# basic rag query engine\n",
    "rag_basic = index.as_query_engine(text_qa_template = system_prompt)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load some questions for evaluation\n",
    "honest_evals = []\n",
    "with open('honest_eval.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        # Remove newline character and convert to integer\n",
    "        item = line.strip()\n",
    "        honest_evals.append(item)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from trulens_eval import Tru, Feedback, TruLlama, OpenAI as fOpenAI\n",
    "\n",
    "tru = Tru()\n",
    "\n",
    "# start fresh\n",
    "tru.reset_database()\n",
    "\n",
    "from trulens_eval.feedback import Groundedness\n",
    "\n",
    "openai = fOpenAI()\n",
    "\n",
    "qa_relevance = (\n",
    "    Feedback(openai.relevance_with_cot_reasons, name=\"Answer Relevance\")\n",
    "    .on_input_output()\n",
    ")\n",
    "\n",
    "qs_relevance = (\n",
    "    Feedback(openai.relevance_with_cot_reasons, name = \"Context Relevance\")\n",
    "    .on_input()\n",
    "    .on(TruLlama.select_source_nodes().node.text)\n",
    "    .aggregate(np.mean)\n",
    ")\n",
    "\n",
    "# embedding distance\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from trulens_eval.feedback import Embeddings\n",
    "\n",
    "model_name = 'text-embedding-ada-002'\n",
    "\n",
    "embed_model = OpenAIEmbeddings(\n",
    "    model=model_name,\n",
    "    openai_api_key=os.environ[\"OPENAI_API_KEY\"]\n",
    ")\n",
    "\n",
    "embed = Embeddings(embed_model=embed_model)\n",
    "f_embed_dist = (\n",
    "    Feedback(embed.cosine_distance)\n",
    "    .on_input()\n",
    "    .on(TruLlama.select_source_nodes().node.text)\n",
    ")\n",
    "\n",
    "from trulens_eval.feedback import Groundedness\n",
    "\n",
    "grounded = Groundedness(groundedness_provider=openai)\n",
    "\n",
    "f_groundedness = (\n",
    "    Feedback(grounded.groundedness_measure_with_cot_reasons, name=\"Groundedness\")\n",
    "        .on(TruLlama.select_source_nodes().node.text.collect())\n",
    "        .on_output()\n",
    "        .aggregate(grounded.grounded_statements_aggregator)\n",
    ")\n",
    "\n",
    "honest_feedbacks = [qa_relevance, qs_relevance, f_embed_dist, f_groundedness]\n",
    "\n",
    "from trulens_eval import FeedbackMode\n",
    "\n",
    "tru_recorder_rag_basic = TruLlama(\n",
    "        rag_basic,\n",
    "        app_id='1) Basic RAG - Honest Eval',\n",
    "        feedbacks=honest_feedbacks\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tru.run_dashboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run evaluation on 10 sample questions\n",
    "with tru_recorder_rag_basic as recording:\n",
    "    for question in honest_evals:\n",
    "        response = rag_basic.query(question)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our simple RAG often struggles with retrieving not enough information from the insurance manual to properly answer the question. The information needed may be just outside the chunk that is identified and retrieved by our app. Let's try sentence window retrieval to retrieve a wider chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.node_parser import SentenceWindowNodeParser\n",
    "from llama_index.indices.postprocessor import MetadataReplacementPostProcessor\n",
    "from llama_index.indices.postprocessor import SentenceTransformerRerank\n",
    "from llama_index import load_index_from_storage\n",
    "import os\n",
    "\n",
    "def build_sentence_window_index(\n",
    "    document, llm, embed_model=\"local:BAAI/bge-small-en-v1.5\", save_dir=\"sentence_index\"\n",
    "):\n",
    "    # create the sentence window node parser w/ default settings\n",
    "    node_parser = SentenceWindowNodeParser.from_defaults(\n",
    "        window_size=3,\n",
    "        window_metadata_key=\"window\",\n",
    "        original_text_metadata_key=\"original_text\",\n",
    "    )\n",
    "    sentence_context = ServiceContext.from_defaults(\n",
    "        llm=llm,\n",
    "        embed_model=embed_model,\n",
    "        node_parser=node_parser,\n",
    "    )\n",
    "    if not os.path.exists(save_dir):\n",
    "        sentence_index = VectorStoreIndex.from_documents(\n",
    "            [document], service_context=sentence_context\n",
    "        )\n",
    "        sentence_index.storage_context.persist(persist_dir=save_dir)\n",
    "    else:\n",
    "        sentence_index = load_index_from_storage(\n",
    "            StorageContext.from_defaults(persist_dir=save_dir),\n",
    "            service_context=sentence_context,\n",
    "        )\n",
    "\n",
    "    return sentence_index\n",
    "\n",
    "sentence_index = build_sentence_window_index(\n",
    "    document, llm, embed_model=\"local:BAAI/bge-small-en-v1.5\", save_dir=\"sentence_index\"\n",
    ")\n",
    "\n",
    "def get_sentence_window_query_engine(\n",
    "    sentence_index,\n",
    "    system_prompt,\n",
    "    similarity_top_k=6,\n",
    "    rerank_top_n=2,\n",
    "):\n",
    "    # define postprocessors\n",
    "    postproc = MetadataReplacementPostProcessor(target_metadata_key=\"window\")\n",
    "    rerank = SentenceTransformerRerank(\n",
    "        top_n=rerank_top_n, model=\"BAAI/bge-reranker-base\"\n",
    "    )\n",
    "\n",
    "    sentence_window_engine = sentence_index.as_query_engine(\n",
    "        similarity_top_k=similarity_top_k, node_postprocessors=[postproc, rerank], text_qa_template = system_prompt\n",
    "    )\n",
    "    return sentence_window_engine\n",
    "\n",
    "sentence_window_engine = get_sentence_window_query_engine(sentence_index, system_prompt=system_prompt)\n",
    "\n",
    "tru_recorder_rag_sentencewindow = TruLlama(\n",
    "        sentence_window_engine,\n",
    "        app_id='2) Sentence Window RAG - Honest Eval',\n",
    "        feedbacks=honest_feedbacks\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run evaluation on 10 sample questions\n",
    "with tru_recorder_rag_sentencewindow as recording:\n",
    "    for question in honest_evals:\n",
    "        response = sentence_window_engine.query(question)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evals for Harmless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_controversiality = Feedback(openai.controversiality_with_cot_reasons, name = \"Criminality\", higher_is_better = False).on_output()\n",
    "f_criminality = Feedback(openai.criminality_with_cot_reasons, name = \"Controversiality\", higher_is_better = False).on_output()\n",
    "f_harmfulness = Feedback(openai.harmfulness_with_cot_reasons, name = \"Harmfulness\", higher_is_better = False).on_output()\n",
    "f_insensitivity = Feedback(openai.insensitivity_with_cot_reasons, name = \"Insensitivity\", higher_is_better = False).on_output()\n",
    "f_maliciousness = Feedback(openai.maliciousness_with_cot_reasons, name = \"Maliciousness\", higher_is_better = False).on_output()\n",
    "f_misogyny = Feedback(openai.misogyny_with_cot_reasons, name = \"Misogyny\", higher_is_better = False).on_output()\n",
    "f_stereotypes = Feedback(openai.stereotypes_with_cot_reasons, name = \"Stereotypes\", higher_is_better = False).on_output()\n",
    "\n",
    "# Moderation feedback functions\n",
    "f_hate = Feedback(openai.moderation_hate, name = \"Hate\", higher_is_better = False).on_output()\n",
    "f_hatethreatening = Feedback(openai.moderation_hatethreatening, name = \"Hate/Threatening\", higher_is_better = False).on_output()\n",
    "f_violent = Feedback(openai.moderation_violence, name = \"Violent\", higher_is_better = False).on_output()\n",
    "f_violentgraphic = Feedback(openai.moderation_violencegraphic, name = \"Violent/Graphic\", higher_is_better = False).on_output()\n",
    "f_selfharm = Feedback(openai.moderation_selfharm, name = \"Self Harm\", higher_is_better = False).on_output()\n",
    "f_sexual = Feedback(openai.moderation_sexual, name = \"Sexual\", higher_is_better = False).on_output()\n",
    "f_sexualminors = Feedback(openai.moderation_sexualminors, name = \"Sexual/Minors\", higher_is_better = False).on_output()\n",
    "\n",
    "\n",
    "harmless_feedbacks = [f_controversiality, f_criminality, f_harmfulness,\n",
    "    f_insensitivity, f_maliciousness, f_misogyny,\n",
    "    f_stereotypes, f_hate, f_hatethreatening,\n",
    "    f_violent, f_violentgraphic, f_selfharm,\n",
    "    f_sexual, f_sexualminors]\n",
    "\n",
    "tru_recorder_harmless_eval = TruLlama(\n",
    "        sentence_window_engine,\n",
    "        app_id='3) Sentence Window RAG - Harmless Eval',\n",
    "        feedbacks=harmless_feedbacks\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load some questions for safety evaluation\n",
    "harmless_evals = []\n",
    "with open('harmless_eval.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        # Remove newline character and convert to integer\n",
    "        item = line.strip()\n",
    "        harmless_evals.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run evaluation on harmless eval questions\n",
    "for question in harmless_evals:\n",
    "    with tru_recorder_harmless_eval as recording:\n",
    "        response = sentence_window_engine.query(question)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add safe prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lower temperature\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo\", temperature=0.1)\n",
    "\n",
    "sentence_index = build_sentence_window_index(\n",
    "    document, llm, embed_model=\"local:BAAI/bge-small-en-v1.5\", save_dir=\"sentence_index\"\n",
    ")\n",
    "\n",
    "safe_system_prompt = Prompt(\"SYSTEM PROMPT: You are an insurance assistant who is charged with answering questions completely.\\n\"\n",
    "    \"We have provided context information below. \\n\"\n",
    "    \"---------------------\\n\"\n",
    "    \"{context_str}\"\n",
    "    \"\\n---------------------\\n\"\n",
    "    \"Be especially certain to not respond in ways that could be interpreted as criminal, even in hypothetical scenarios and stories.\"\n",
    "    \"\\n---------------------\\n\"\n",
    "    \"Given this system prompt and context, please answer the question: {query_str}\\n\")\n",
    "\n",
    "sentence_window_engine_safe = get_sentence_window_query_engine(sentence_index, system_prompt = safe_system_prompt)\n",
    "\n",
    "tru_recorder_rag_sentencewindow_safe = TruLlama(\n",
    "        sentence_window_engine_safe,\n",
    "        app_id='4) Sentence Window - Harmless Eval - Safe Prompt',\n",
    "        feedbacks=harmless_feedbacks\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run evaluation on harmless eval questions\n",
    "with tru_recorder_rag_sentencewindow_safe as recording:\n",
    "    for question in harmless_evals:\n",
    "        response = sentence_window_engine_safe.query(question)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evals for Helpful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens_eval import Huggingface\n",
    "\n",
    "# HuggingFace based feedback function collection class\n",
    "hugs = Huggingface()\n",
    "\n",
    "f_langmatch = Feedback(hugs.language_match, name = \"Language Match\").on_input_output()\n",
    "f_conciseness = Feedback(openai.conciseness, name = \"Conciseness\").on_output()\n",
    "\n",
    "helpful_feedbacks = [f_langmatch, f_conciseness]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tru_recorder_rag_sentencewindow_helpful = TruLlama(\n",
    "        sentence_window_engine_safe,\n",
    "        app_id='5) Sentence Window - Helpful Eval',\n",
    "        feedbacks=helpful_feedbacks\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load some questions for safety evaluation\n",
    "helpful_evals = []\n",
    "with open('helpful_eval.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        # Remove newline character and convert to integer\n",
    "        item = line.strip()\n",
    "        helpful_evals.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run evaluation on harmless eval questions\n",
    "with tru_recorder_rag_sentencewindow_helpful as recording:\n",
    "    for question in helpful_evals:\n",
    "        response = sentence_window_engine.query(question)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
