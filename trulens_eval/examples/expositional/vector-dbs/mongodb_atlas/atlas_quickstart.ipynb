{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MongoDB Atlas Quickstart\n",
    "\n",
    "[MongoDB Atlas Vector Search](https://www.mongodb.com/products/platform/atlas-vector-search) is part of the MongoDB platform that enables MongoDB customers to build intelligent applications powered by semantic search over any type of data. Atlas Vector Search allows you to integrate your operational database and vector search in a single, unified, fully managed platform with full vector database capabilities.\n",
    "\n",
    "You can integrate TruLens with your application built on Atlas Vector Search to leverage observability and measure improvements in your application's search capabilities.\n",
    "\n",
    "This tutorial will walk you through the process of setting up TruLens with MongoDB Atlas Vector Search and Llama-Index as the orchestrator.\n",
    "\n",
    "Even better, you'll learn how to use metadata filters to create specialized query engines and leverage a router to choose the most appropriate query engine based on the query.\n",
    "\n",
    "See [MongoDB Atlas/LlamaIndex Quickstart](https://www.mongodb.com/docs/atlas/atlas-vector-search/ai-integrations/llamaindex/) for more details.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/truera/trulens/blob/main/trulens_eval/examples/expositional/vector-dbs/mongodb_atlas/atlas_quickstart.ipynb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install trulens-eval llama-index llama-index-vector-stores-mongodb llama-index-embeddings-openai pymongo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import TruLens and start the dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jreini/opt/anaconda3/envs/trulens_dev_empty/lib/python3.11/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦‘ Tru initialized with db url sqlite:///default.sqlite .\n",
      "ðŸ›‘ Secret keys may be written to the database. See the `database_redact_keys` option of Tru` to prevent this.\n",
      "Starting dashboard ...\n",
      "Config file already exists. Skipping writing process.\n",
      "Credentials file already exists. Skipping writing process.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ac29f1d94da4896903fea8e3b565857",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Accordion(children=(VBox(children=(VBox(children=(Label(value='STDOUT'), Output())), VBox(children=(Label(valuâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dashboard started at http://192.168.4.23:8501 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Popen: returncode: None args: ['streamlit', 'run', '--server.headless=True'...>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from trulens_eval import Tru\n",
    "\n",
    "tru = Tru()\n",
    "\n",
    "tru.reset_database()\n",
    "\n",
    "tru.run_dashboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set imports, keys and llama-index settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass, os, pymongo, pprint\n",
    "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex, StorageContext\n",
    "from llama_index.core.settings import Settings\n",
    "from llama_index.core.retrievers import VectorIndexRetriever\n",
    "from llama_index.core.vector_stores import MetadataFilter, MetadataFilters, ExactMatchFilter, FilterOperator\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.vector_stores.mongodb import MongoDBAtlasVectorSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-...\"\n",
    "ATLAS_CONNECTION_STRING = \"mongodb+srv://<username>:<password>@<clusterName>.<hostname>.mongodb.net\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Settings.llm = OpenAI()\n",
    "Settings.embed_model = OpenAIEmbedding(model=\"text-embedding-ada-002\")\n",
    "Settings.chunk_size = 100\n",
    "Settings.chunk_overlap = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load sample data\n",
    "\n",
    "Here we'll load two PDFs: one for Atlas best practices and one textbook on database essentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-04-05 16:06:56--  https://query.prod.cms.rt.microsoft.com/cms/api/am/binary/RE4HkJP\n",
      "Resolving query.prod.cms.rt.microsoft.com (query.prod.cms.rt.microsoft.com)... 23.47.30.189\n",
      "Connecting to query.prod.cms.rt.microsoft.com (query.prod.cms.rt.microsoft.com)|23.47.30.189|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: unspecified [application/pdf]\n",
      "Saving to: â€˜data/atlas_best_practices.pdfâ€™\n",
      "\n",
      "data/atlas_best_pra     [ <=>                ] 500.64K  --.-KB/s    in 0.04s   \n",
      "\n",
      "2024-04-05 16:06:56 (11.2 MB/s) - â€˜data/atlas_best_practices.pdfâ€™ saved [512653]\n",
      "\n",
      "--2024-04-05 16:06:56--  http://fondamentidibasididati.it/wp-content/uploads/2020/11/DBEssential-2021-C30-11-21.pdf\n",
      "Resolving fondamentidibasididati.it (fondamentidibasididati.it)... 157.138.8.2\n",
      "Connecting to fondamentidibasididati.it (fondamentidibasididati.it)|157.138.8.2|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 595602 (582K) [application/pdf]\n",
      "Saving to: â€˜data/DBEssential-2021.pdfâ€™\n",
      "\n",
      "data/DBEssential-20 100%[===================>] 581.64K   914KB/s    in 0.6s    \n",
      "\n",
      "2024-04-05 16:06:57 (914 KB/s) - â€˜data/DBEssential-2021.pdfâ€™ saved [595602/595602]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the sample data\n",
    "!mkdir -p 'data/'\n",
    "!wget 'https://query.prod.cms.rt.microsoft.com/cms/api/am/binary/RE4HkJP' -O 'data/atlas_best_practices.pdf'\n",
    "atlas_best_practices = SimpleDirectoryReader(input_files=[\"./data/atlas_best_practices.pdf\"]).load_data()\n",
    "\n",
    "!wget 'http://fondamentidibasididati.it/wp-content/uploads/2020/11/DBEssential-2021-C30-11-21.pdf' -O 'data/DBEssential-2021.pdf'\n",
    "db_essentials = SimpleDirectoryReader(input_files=[\"./data/DBEssential-2021.pdf\"]).load_data()\n",
    "\n",
    "documents = atlas_best_practices + db_essentials\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a vector store\n",
    "\n",
    "Next you need to create an Atlas Vector Search Index.\n",
    "\n",
    "When you do so, use the following in the json editor:\n",
    "\n",
    "```\n",
    "{\n",
    "  \"fields\": [\n",
    "    {\n",
    "      \"numDimensions\": 1536,\n",
    "      \"path\": \"embedding\",\n",
    "      \"similarity\": \"cosine\",\n",
    "      \"type\": \"vector\"\n",
    "    },\n",
    "    {\n",
    "      \"path\": \"metadata.file_name\",\n",
    "      \"type\": \"filter\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "969f14f3a741474d998a3fc7a6393a23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/133 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3685b3942e6d4d4d99cb00e4e4a37a2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/1144 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Connect to your Atlas cluster\n",
    "mongodb_client = pymongo.MongoClient(ATLAS_CONNECTION_STRING)\n",
    "\n",
    "# Instantiate the vector store\n",
    "atlas_vector_search = MongoDBAtlasVectorSearch(\n",
    "    mongodb_client,\n",
    "    db_name = \"atlas-best-practices\",\n",
    "    collection_name = \"test\",\n",
    "    index_name = \"vector_index\"\n",
    ")\n",
    "vector_store_context = StorageContext.from_defaults(vector_store=atlas_vector_search)\n",
    "\n",
    "# load both documents into the vector store\n",
    "vector_store_index = VectorStoreIndex.from_documents(\n",
    "   documents, storage_context=vector_store_context, show_progress=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup basic RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = vector_store_index.as_query_engine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add feedback functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… In Groundedness, input source will be set to __record__.app.query.rets.source_nodes[:].node.text.collect() .\n",
      "âœ… In Groundedness, input statement will be set to __record__.main_output or `Select.RecordOutput` .\n",
      "âœ… In Answer Relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
      "âœ… In Answer Relevance, input response will be set to __record__.main_output or `Select.RecordOutput` .\n",
      "âœ… In Context Relevance, input question will be set to __record__.main_input or `Select.RecordInput` .\n",
      "âœ… In Context Relevance, input context will be set to __record__.app.query.rets.source_nodes[:].node.text .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/jreini/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from trulens_eval.feedback.provider import OpenAI\n",
    "from trulens_eval import Feedback\n",
    "import numpy as np\n",
    "\n",
    "# Initialize provider class\n",
    "provider = OpenAI()\n",
    "\n",
    "# select context to be used in feedback. the location of context is app specific.\n",
    "from trulens_eval.app import App\n",
    "context = App.select_context(query_engine)\n",
    "\n",
    "from trulens_eval.feedback import Groundedness\n",
    "grounded = Groundedness(groundedness_provider=OpenAI())\n",
    "# Define a groundedness feedback function\n",
    "f_groundedness = (\n",
    "    Feedback(grounded.groundedness_measure_with_cot_reasons, name = \"Groundedness\")\n",
    "    .on(context.collect()) # collect context chunks into a list\n",
    "    .on_output()\n",
    "    .aggregate(grounded.grounded_statements_aggregator)\n",
    ")\n",
    "\n",
    "# Question/answer relevance between overall question and answer.\n",
    "f_answer_relevance = (\n",
    "    Feedback(provider.relevance_with_cot_reasons, name = \"Answer Relevance\")\n",
    "    .on_input_output()\n",
    ")\n",
    "# Context relevance between question and each context chunk.\n",
    "f_context_relevance = (\n",
    "    Feedback(provider.context_relevance_with_cot_reasons, name = \"Context Relevance\")\n",
    "    .on_input()\n",
    "    .on(context)\n",
    "    .aggregate(np.mean)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens_eval import TruLlama\n",
    "tru_query_engine_recorder = TruLlama(query_engine,\n",
    "    app_id='Basic RAG',\n",
    "    feedbacks=[f_groundedness, f_answer_relevance, f_context_relevance])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write test cases\n",
    "\n",
    "Let's write a few test queries to test the ability of our RAG to answer questions on both documents in the vector store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens_eval.generate_test_set import GenerateTestSet\n",
    "\n",
    "test_set = {'MongoDB Atlas': [\n",
    "                \"How do you secure MongoDB Atlas?\",\n",
    "                \"How can Time to Live (TTL) be used to expire data in MongoDB Atlas?\"],\n",
    "            'Database Essentials': [\n",
    "                \"Why might I use a relational data model?\",\n",
    "                \"What is the impact of interleaving transactions in database operations?\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get testing!\n",
    "\n",
    "Our test set is made up of 2 topics (test breadth), each with 2 questions (test depth).\n",
    "\n",
    "We can store the topic as record level metadata and then test queries from each topic, using `tru_query_engine_recorder` as a context manager."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a59a99e3e574996b2d579dd88b76348",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73f9705c97a247c6a3f08975960acc29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7284fcf9ad649dba9e2353bf4060ff6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56952bb60e3b4d39a3d2d158f836e23a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with tru_query_engine_recorder as recording:\n",
    "    for category in test_set:\n",
    "        recording.record_metadata=dict(prompt_category=category)\n",
    "        test_prompts = test_set[category]\n",
    "        for test_prompt in test_prompts:\n",
    "            response = query_engine.query(test_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check evaluation results\n",
    "\n",
    "Evaluation results can be viewed in the TruLens dashboard (started at the top of the notebook) or directly in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Groundedness</th>\n",
       "      <th>Answer Relevance</th>\n",
       "      <th>Context Relevance</th>\n",
       "      <th>latency</th>\n",
       "      <th>total_cost</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>app_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Basic RAG</th>\n",
       "      <td>0.625</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.85</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.000388</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Groundedness  Answer Relevance  Context Relevance  latency  \\\n",
       "app_id                                                                  \n",
       "Basic RAG         0.625             0.775               0.85     1.25   \n",
       "\n",
       "           total_cost  \n",
       "app_id                 \n",
       "Basic RAG    0.000388  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tru.get_leaderboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perhaps if we use metadata filters to create specialized query engines, we can improve the search results and thus, the overall evaluation results.\n",
    "\n",
    "But it may be clunky to have two separate query engines - then we have to decide which one to use!\n",
    "\n",
    "Instead, let's use a router query engine to choose the query engine based on the query.\n",
    "\n",
    "## Router Query Engine + Metadata Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify metadata filters\n",
    "metadata_filters_db_essentials = MetadataFilters(\n",
    "   filters=[ExactMatchFilter(key=\"metadata.file_name\", value=\"DBEssential-2021.pdf\")]\n",
    ")\n",
    "metadata_filters_atlas = MetadataFilters(\n",
    "   filters=[ExactMatchFilter(key=\"metadata.file_name\", value=\"atlas_best_practices.pdf\")]\n",
    ")\n",
    "\n",
    "# Instantiate Atlas Vector Search as a retriever for each set of filters\n",
    "vector_store_retriever_db_essentials = VectorIndexRetriever(index=vector_store_index, filters=metadata_filters_db_essentials, similarity_top_k=5)\n",
    "vector_store_retriever_atlas = VectorIndexRetriever(index=vector_store_index, filters=metadata_filters_atlas, similarity_top_k=5)\n",
    "\n",
    "# Pass the retrievers into the query engines\n",
    "query_engine_with_filters_db_essentials = RetrieverQueryEngine(retriever=vector_store_retriever_db_essentials)\n",
    "query_engine_with_filters_atlas = RetrieverQueryEngine(retriever=vector_store_retriever_atlas)\n",
    "\n",
    "from llama_index.core.tools import QueryEngineTool\n",
    "\n",
    "# Set up the two distinct tools (query engines)\n",
    "\n",
    "essentials_tool = QueryEngineTool.from_defaults(\n",
    "    query_engine=query_engine_with_filters_db_essentials,\n",
    "    description=(\n",
    "        \"Useful for retrieving context about database essentials\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "atlas_tool = QueryEngineTool.from_defaults(\n",
    "    query_engine=query_engine_with_filters_atlas,\n",
    "    description=(\n",
    "        \"Useful for retrieving context about MongoDB Atlas\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Create the router query engine\n",
    "\n",
    "from llama_index.core.query_engine import RouterQueryEngine\n",
    "from llama_index.core.selectors import LLMSingleSelector, LLMMultiSelector\n",
    "from llama_index.core.selectors import (\n",
    "    PydanticMultiSelector,\n",
    "    PydanticSingleSelector,\n",
    ")\n",
    "\n",
    "\n",
    "router_query_engine = RouterQueryEngine(\n",
    "    selector=PydanticSingleSelector.from_defaults(),\n",
    "    query_engine_tools=[\n",
    "        essentials_tool,\n",
    "        atlas_tool,\n",
    "    ],\n",
    ")\n",
    "\n",
    "from trulens_eval import TruLlama\n",
    "tru_query_engine_recorder_with_router = TruLlama(router_query_engine,\n",
    "    app_id='Router Query Engine + Filters',\n",
    "    feedbacks=[f_groundedness, f_answer_relevance, f_context_relevance])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6058752dca6c4459b5012891056c5c25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7424520c06f14370a77ff8c462c247b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7c7898ca29041d4acb37920f0ad09ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "219aa7881c64480cba60560075892fed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with tru_query_engine_recorder_with_router as recording:\n",
    "    for category in test_set:\n",
    "        recording.record_metadata=dict(prompt_category=category)\n",
    "        test_prompts = test_set[category]\n",
    "        for test_prompt in test_prompts:\n",
    "            response = router_query_engine.query(test_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Groundedness</th>\n",
       "      <th>Answer Relevance</th>\n",
       "      <th>Context Relevance</th>\n",
       "      <th>latency</th>\n",
       "      <th>total_cost</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>app_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Router Query Engine + Filters</th>\n",
       "      <td>0.725</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.779167</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.000926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Basic RAG</th>\n",
       "      <td>0.625</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.000388</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Groundedness  Answer Relevance  \\\n",
       "app_id                                                          \n",
       "Router Query Engine + Filters         0.725             0.950   \n",
       "Basic RAG                             0.625             0.775   \n",
       "\n",
       "                               Context Relevance  latency  total_cost  \n",
       "app_id                                                                 \n",
       "Router Query Engine + Filters           0.779167     1.25    0.000926  \n",
       "Basic RAG                               0.850000     1.25    0.000388  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tru.get_leaderboard()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trulens_dev_empty",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
