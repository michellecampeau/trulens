{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Connect to SQLite database\n",
    "sqlite_conn = sqlite3.connect(\"default.sqlite\")\n",
    "cursor = sqlite_conn.cursor()\n",
    "\n",
    "# Get the list of all tables\n",
    "cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "tables = cursor.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import snowflake.connector\n",
    "\n",
    "snowflake_conn = snowflake.connector.connect(\n",
    "    account=os.environ.get(\"SNOWFLAKE_ACCOUNT\"),\n",
    "    user=os.environ.get(\"SNOWFLAKE_USER\"),\n",
    "    password=os.environ.get(\"SNOWFLAKE_USER_PASSWORD\"),\n",
    "    database=os.environ.get(\"SNOWFLAKE_DATABASE\"),\n",
    "    schema=\"CONTEXT_RELEVANCE_TREC_COMBINED_NO_RUBRIC\",\n",
    "    warehouse=os.environ.get(\"SNOWFLAKE_WAREHOUSE\"),\n",
    "    role=os.environ.get(\"SNOWFLAKE_ROLE\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for table_name in tables:\n",
    "    # Load data from SQLite into a DataFrame\n",
    "    table_name = table_name[0]  # Extract table name from tuple\n",
    "    df = pd.read_sql_query(f\"SELECT * FROM {table_name}\", sqlite_conn)\n",
    "\n",
    "    # Generate CREATE TABLE statement\n",
    "    create_table_sql = f\"CREATE OR REPLACE TABLE {table_name} (\"\n",
    "    columns = []\n",
    "    for col_name, col_type in df.dtypes.items():\n",
    "        if col_type == \"int64\":\n",
    "            col_type_snowflake = \"INTEGER\"\n",
    "        elif col_type == \"float64\":\n",
    "            col_type_snowflake = \"FLOAT\"\n",
    "        elif col_type == \"bool\":\n",
    "            col_type_snowflake = \"BOOLEAN\"\n",
    "        else:\n",
    "            col_type_snowflake = \"TEXT\"\n",
    "        columns.append(f\"{col_name} {col_type_snowflake}\")\n",
    "    create_table_sql += \", \".join(columns) + \");\"\n",
    "\n",
    "    # Create table in Snowflake\n",
    "    cursor = snowflake_conn.cursor()\n",
    "    cursor.execute(create_table_sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "for table_name in tables:\n",
    "    table_name = table_name[0]\n",
    "    df = pd.read_sql_query(f\"SELECT * FROM {table_name}\", sqlite_conn)\n",
    "\n",
    "    # Save DataFrame as a CSV\n",
    "    csv_file = f\"{table_name}.csv\"\n",
    "    df.to_csv(csv_file, index=False)\n",
    "\n",
    "    # Generate a Snowflake-compatible stage name by replacing special characters with underscores\n",
    "    sanitized_stage_name = re.sub(r\"\\W+\", \"_\", f\"temp_stage_{table_name}\")\n",
    "\n",
    "    # Create a temporary stage in Snowflake\n",
    "    snowflake_cursor = snowflake_conn.cursor()\n",
    "    snowflake_cursor.execute(\n",
    "        f\"CREATE OR REPLACE TEMPORARY STAGE {sanitized_stage_name}\"\n",
    "    )\n",
    "\n",
    "    # PUT the CSV file to the stage\n",
    "    with open(csv_file, \"rb\") as file_data:\n",
    "        snowflake_cursor.execute(\n",
    "            f\"PUT file://{csv_file} @{sanitized_stage_name}\"\n",
    "        )\n",
    "\n",
    "    # Copy data from the stage to the table in Snowflake\n",
    "    snowflake_cursor.execute(f\"\"\"\n",
    "        COPY INTO {table_name}\n",
    "        FROM @{sanitized_stage_name}\n",
    "        FILE_FORMAT = (TYPE = 'CSV' FIELD_OPTIONALLY_ENCLOSED_BY = '\"' SKIP_HEADER = 1)\n",
    "    \"\"\")\n",
    "\n",
    "    # Clean up temporary stage and local CSV file\n",
    "    snowflake_cursor.execute(f\"DROP STAGE IF EXISTS {sanitized_stage_name}\")\n",
    "    os.remove(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlite_conn.close()\n",
    "snowflake_conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def plot_confusion_matrices(csv_file_path: str, title: str):\n",
    "    # Step 1: Load the CSV file\n",
    "    data = pd.read_csv(csv_file_path)\n",
    "\n",
    "    # Step 2: Inspect the data\n",
    "    print(data.head())\n",
    "\n",
    "    # Ensure your CSV has columns: 'APP_VERSION', 'RAW_GT_SCORE', 'RAW_FEEDBACK_SCORE', and 'COUNT'\n",
    "\n",
    "    # Step 3: Group data by 'APP_VERSION' and create a confusion matrix for each version\n",
    "    app_versions = data[\"APP_VERSION\"].unique()  # Get unique app versions\n",
    "\n",
    "    for app_version in app_versions:\n",
    "        # Filter data for the current app version\n",
    "        app_data = data[data[\"APP_VERSION\"] == app_version]\n",
    "\n",
    "        # Pivot the data to create a confusion matrix\n",
    "        confusion_matrix = app_data.pivot(\n",
    "            index=\"RAW_GT_SCORE\", columns=\"RAW_FEEDBACK_SCORE\", values=\"COUNT\"\n",
    "        ).fillna(0)\n",
    "\n",
    "        # Normalize the confusion matrix (optional)\n",
    "        confusion_matrix_normalized = confusion_matrix.div(\n",
    "            confusion_matrix.sum(axis=1), axis=0\n",
    "        )\n",
    "\n",
    "        # Step 4: Plot the confusion matrix for the current app version\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(confusion_matrix, annot=True, fmt=\".0f\", cmap=\"Blues\")\n",
    "        plt.title(f\"{title}: {app_version}\")\n",
    "        plt.xlabel(\"Feedback Score\")\n",
    "        plt.ylabel(\"Ground Truth\")\n",
    "        plt.show()\n",
    "\n",
    "        # Step 5: Plot the normalized confusion matrix for the current app version\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(\n",
    "            confusion_matrix_normalized, annot=True, fmt=\".2f\", cmap=\"Blues\"\n",
    "        )\n",
    "        plt.title(f\"Normalized {title}: {app_version}\")\n",
    "        plt.xlabel(\"Feedback Score\")\n",
    "        plt.ylabel(\"Ground Truth\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_with_rubric = \"/Users/dhuang/Documents/git/trulens/src/benchmark/trulens/benchmark/benchmark_frameworks/experiments/data/TREC_rubric.csv\"\n",
    "csv_file_no_rubric = \"/Users/dhuang/Documents/git/trulens/src/benchmark/trulens/benchmark/benchmark_frameworks/experiments/data/TREC_no_rubric.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrices(csv_file_no_rubric, \"Original prompt for\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trulens",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
